{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBebl4rh4SRF"
      },
      "source": [
        "Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kPlEupg4SRJ",
        "outputId": "d30a17f2-6686-4608-9d4e-6f342b0dc9a5"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import sys\n",
        "import random\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "import mediapipe as mp\n",
        "import torch\n",
        "import timm\n",
        "import math\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.autonotebook import tqdm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfZw-kjb4SRM"
      },
      "source": [
        "Functions to Load Video Names and Labels from CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K9EfKXp4SRN"
      },
      "outputs": [],
      "source": [
        "# Define a custom dataset class for loading video frames and labels\n",
        "class video_dataset(Dataset):\n",
        "    def __init__(self, video_names, labels, sequence_length=60, transform=None):\n",
        "        self.video_names = video_names  \n",
        "        self.labels = labels  \n",
        "        self.transform = transform \n",
        "        self.count = sequence_length  \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.video_names)  \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        video_path = self.video_names[idx] \n",
        "        frames = []\n",
        "        a = int(100 / self.count)  # Calculate the range for random starting frame\n",
        "        first_frame = np.random.randint(0, a) \n",
        "        temp_video = video_path.split('/')[-1]  \n",
        "        label = lab.loc[lab[\"file\"] == temp_video, \"label\"].values \n",
        "\n",
        "        if label == 'FAKE':\n",
        "            label = 0\n",
        "        if label == 'REAL':\n",
        "            label = 1\n",
        "\n",
        "        # Extract frames from the video\n",
        "        for i, frame in enumerate(self.frame_extract(video_path)):\n",
        "            frames.append(self.transform(frame)) \n",
        "            if len(frames) == self.count:\n",
        "                break\n",
        "\n",
        "        frames = torch.stack(frames)  # Convert list of frames to a tensor\n",
        "        frames = frames[:self.count] \n",
        "        return frames, label \n",
        "\n",
        "    def frame_extract(self, path):\n",
        "        vidObj = cv2.VideoCapture(path)\n",
        "        success = 1\n",
        "        while success:\n",
        "            success, image = vidObj.read()  \n",
        "            if success:\n",
        "                yield image  \n",
        "\n",
        "# Function to plot an image tensor\n",
        "def im_plot(tensor):\n",
        "    image = tensor.cpu().numpy().transpose(1, 2, 0)  # Convert tensor to numpy array and reorder dimensions\n",
        "    b, g, r = cv2.split(image)\n",
        "    image = cv2.merge((r, g, b))\n",
        "    image = image * [0.22803, 0.22145, 0.216989] + [0.43216, 0.394666, 0.37645]  \n",
        "    image = image * 255.0 \n",
        "    plt.imshow(image.astype(int))\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Pxxd44Q4SRO"
      },
      "source": [
        "Function to Count Real and Fake Videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0lm3xFv4SRP"
      },
      "outputs": [],
      "source": [
        "def number_of_real_and_fake_videos(data_list):\n",
        "    header_list = [\"file\", \"label\"]\n",
        "    # Load the CSV file containing video file names and labels\n",
        "    lab = pd.read_csv('/content/drive/MyDrive/labels.csv', names=header_list)\n",
        "\n",
        "    fake = 0\n",
        "    real = 0\n",
        "\n",
        "    for files_pattern in data_list:\n",
        "        # Get all file paths that match the pattern\n",
        "        file_paths = glob.glob(files_pattern)\n",
        "        for file_path in file_paths:\n",
        "            temp_video = os.path.basename(file_path) \n",
        "\n",
        "            # Get the label for the video\n",
        "            label = lab.loc[lab[\"file\"] == temp_video, \"label\"].values\n",
        "\n",
        "            if len(label) > 0:\n",
        "                label = label[0]\n",
        "                if label == 'FAKE':\n",
        "                    fake += 1\n",
        "                elif label == 'REAL':\n",
        "                    real += 1\n",
        "            else:\n",
        "                print(f\"No label found for {temp_video}\")\n",
        "\n",
        "    return real, fake\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU1tnoy_4SRP"
      },
      "source": [
        "Function to Define and Load Data Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnTq1H6F4SRQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_data_transforms():\n",
        "    im_size = 112 \n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "\n",
        "    # Define transformations for training data\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.ToPILImage(),  \n",
        "        transforms.Resize((im_size, im_size)),\n",
        "        transforms.ToTensor(),  \n",
        "        transforms.Normalize(mean, std) \n",
        "    ])\n",
        "\n",
        "    # Define transformations for testing data\n",
        "    test_transforms = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((im_size, im_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ])\n",
        "\n",
        "    return train_transforms, test_transforms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl3h_lyP4SRQ"
      },
      "source": [
        "Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bme3nvsIK2yo"
      },
      "outputs": [],
      "source": [
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=100):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, latent_dim=512, num_heads=2, num_layers=1, hidden_dim=256):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=latent_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=hidden_dim,\n",
        "            dropout=0.5,\n",
        "            activation=\"gelu\",\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.norm = nn.LayerNorm(latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.norm(x)\n",
        "        return self.transformer_encoder(x)\n",
        "\n",
        "class DeepfakeModel(nn.Module):\n",
        "    def __init__(self, num_classes, latent_dim=512, num_heads=2, num_layers=1, hidden_dim=256, max_seq_len=20):\n",
        "        super(DeepfakeModel, self).__init__()\n",
        "\n",
        "        base_model = timm.create_model('efficientnet_b3', pretrained=True)\n",
        "        self.feature_extractor = nn.Sequential(*list(base_model.children())[:-2])\n",
        "\n",
        "        feat_dim = 1536\n",
        "\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(1),\n",
        "            nn.Linear(feat_dim, latent_dim),\n",
        "            nn.LayerNorm(latent_dim),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.pos_encoder = PositionalEncoding(latent_dim, dropout=0.2, max_len=max_seq_len)\n",
        "\n",
        "        self.transformer = TransformerEncoder(\n",
        "            latent_dim=latent_dim,\n",
        "            num_heads=num_heads,\n",
        "            num_layers=num_layers,\n",
        "            hidden_dim=hidden_dim\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "        self.temporal_pool = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "    def forward(self, x, return_features=False):\n",
        "        batch_size, seq_length, c, h, w = x.shape\n",
        "        # Subsample frames to reduce computation\n",
        "        sample_rate = 2  \n",
        "        if seq_length > 10:\n",
        "            x = x[:, ::sample_rate, :, :, :]\n",
        "            seq_length = x.shape[1]\n",
        "\n",
        "        x = x.view(batch_size * seq_length, c, h, w)\n",
        "        x = self.feature_extractor(x)\n",
        "        x = self.projection(x)\n",
        "        x = x.view(batch_size, seq_length, -1)\n",
        "        x = self.pos_encoder(x)\n",
        "        features = self.transformer(x)\n",
        "        x = features.transpose(1, 2)  # [B, D, T]\n",
        "        x = self.temporal_pool(x).squeeze(-1)  # [B, D]\n",
        "        output = self.classifier(x)\n",
        "\n",
        "        if return_features:\n",
        "            return output, features\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPWJZvuQ4SRR"
      },
      "outputs": [],
      "source": [
        "model = DeepfakeModel(num_classes=2).cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4H-2IweC4SRS"
      },
      "source": [
        "Functions For Training, Testing and Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfBo6AO7OzG-"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "    precision = precision_score(y_true, y_pred) * 100\n",
        "    recall = recall_score(y_true, y_pred) * 100\n",
        "    f1 = f1_score(y_true, y_pred) * 100\n",
        "    roc_auc = roc_auc_score(y_true, y_pred) * 100\n",
        "    return accuracy, precision, recall, f1, roc_auc\n",
        "\n",
        "def calculate_accuracy(outputs, targets):\n",
        "    batch_size = targets.size(0)\n",
        "    _, pred = outputs.topk(1, 1, True)  \n",
        "    pred = pred.t()  \n",
        "    correct = pred.eq(targets.view(1, -1))  # Compare predictions to targets\n",
        "    n_correct_elems = correct.float().sum().item()  # Count correct predictions\n",
        "    return 100 * n_correct_elems / batch_size \n",
        "\n",
        "class AverageMeter(object):\n",
        "    # Computes and stores the average and current value\n",
        "    def __init__(self):\n",
        "        self.reset()  \n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0  \n",
        "        self.sum = 0 \n",
        "        self.count = 0  \n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val  \n",
        "        self.sum += val * n  \n",
        "        self.count += n  \n",
        "        self.avg = self.sum / self.count "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hl7QA2BM4SRS"
      },
      "outputs": [],
      "source": [
        "def train_epoch(epoch, num_epochs, data_loader, model, criterion, optimizer, scaler=None):\n",
        "    model.train()\n",
        "    losses = AverageMeter()\n",
        "    accuracies = AverageMeter()\n",
        "\n",
        "    for i, (inputs, targets) in enumerate(data_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            targets = targets.type(torch.cuda.LongTensor)  # Move targets to GPU and convert to LongTensor\n",
        "            inputs = inputs.cuda()  \n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if scaler is not None:\n",
        "            # Mixed precision training\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "            acc = calculate_accuracy(outputs, targets)\n",
        "            losses.update(loss.item(), inputs.size(0))\n",
        "            accuracies.update(acc, inputs.size(0))\n",
        "            scaler.scale(loss).backward()  # Mixed precision backward and optimizer step           \n",
        "            scaler.unscale_(optimizer) # Unscale gradients for gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # Gradient clipping to prevent exploding gradients\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "        else:\n",
        "            # Standard precision training\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            acc = calculate_accuracy(outputs, targets)\n",
        "            losses.update(loss.item(), inputs.size(0))\n",
        "            accuracies.update(acc, inputs.size(0))\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "        sys.stdout.write(\n",
        "            \"\\r[Epoch %d/%d] [Batch %d / %d] [Loss: %f, Acc: %.2f%%]\"\n",
        "            % (\n",
        "                epoch,\n",
        "                num_epochs,\n",
        "                i,\n",
        "                len(data_loader),\n",
        "                losses.avg,\n",
        "                accuracies.avg))\n",
        "\n",
        "    return losses.avg, accuracies.avg\n",
        "\n",
        "def test(epoch, model, data_loader, criterion, scaler=None):\n",
        "    print('\\nTesting')\n",
        "    model.eval()\n",
        "    losses = AverageMeter()\n",
        "    accuracies = AverageMeter()\n",
        "    pred = []\n",
        "    true = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, targets) in enumerate(data_loader):\n",
        "            if torch.cuda.is_available():\n",
        "                targets = targets.cuda().type(torch.cuda.LongTensor)\n",
        "                inputs = inputs.cuda()\n",
        "\n",
        "            # Use mixed precision for inference if scaler is provided\n",
        "            if scaler is not None:\n",
        "                with torch.amp.autocast('cuda'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, targets)\n",
        "            else:\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "            acc = calculate_accuracy(outputs, targets)\n",
        "            _, p = torch.max(outputs, 1)\n",
        "\n",
        "            # Track predictions and ground truth\n",
        "            true.extend(targets.detach().cpu().numpy().tolist())\n",
        "            pred.extend(p.detach().cpu().numpy().tolist())\n",
        "\n",
        "            losses.update(loss.item(), inputs.size(0))\n",
        "            accuracies.update(acc, inputs.size(0))\n",
        "\n",
        "            sys.stdout.write(\"\\r[Batch %d / %d] [Loss: %f, Acc: %.2f%%]\" %\n",
        "                            (i, len(data_loader), losses.avg, accuracies.avg))\n",
        "\n",
        "    # Calculate detailed evaluation metrics\n",
        "    accuracy, precision, recall, f1, roc_auc = calculate_metrics(true, pred)\n",
        "    print(f\"\\nAccuracy: {accuracy:.2f}% | Precision: {precision:.2f}% | Recall: {recall:.2f}% | F1-Score: {f1:.2f}% | ROC-AUC: {roc_auc:.2f}%\")\n",
        "\n",
        "    return true, pred, losses.avg, accuracies.avg, precision, recall, f1, roc_auc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RmkdkTW4SRT"
      },
      "source": [
        "Functions to Plot Confusion Matrix, Loss and Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fM1i4fOf4SRT"
      },
      "outputs": [],
      "source": [
        "\n",
        "def print_confusion_matrix(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    labels = ['Fake', 'Real']\n",
        "\n",
        "    print(f\"True Positive: {cm[1][1]} | False Positive: {cm[0][1]}\")\n",
        "    print(f\"False Negative: {cm[1][0]} | True Negative: {cm[0][0]}\\n\")\n",
        "\n",
        "    df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "    sn.set(font_scale=1.4)\n",
        "    sn.heatmap(df_cm, annot=True, cmap=\"Blues\", fmt=\"d\", annot_kws={\"size\": 16})\n",
        "    plt.ylabel('Actual Label', size=14)\n",
        "    plt.xlabel('Predicted Label', size=14)\n",
        "    plt.title(\"Confusion Matrix\", size=16)\n",
        "    plt.show()\n",
        "\n",
        "    calculated_acc = (cm[0][0] + cm[1][1]) / (cm[0][0] + cm[0][1] + cm[1][0] + cm[1][1])\n",
        "    print(\"Calculated Accuracy\", calculated_acc * 100)\n",
        "\n",
        "# Function to plot training and validation loss\n",
        "def plot_loss(train_loss_avg, test_loss_avg, num_epochs):\n",
        "    loss_train = train_loss_avg \n",
        "    loss_val = test_loss_avg  \n",
        "    epochs = range(1, num_epochs + 1) \n",
        "\n",
        "    plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "    plt.plot(epochs, loss_val, 'b', label='Validation loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Function to plot training and validation accuracy\n",
        "def plot_accuracy(train_accuracy, test_accuracy, num_epochs):\n",
        "    accuracy_train = train_accuracy  \n",
        "    accuracy_val = test_accuracy  \n",
        "    epochs = range(1, num_epochs + 1)  \n",
        "\n",
        "    plt.plot(epochs, accuracy_train, 'g', label='Training accuracy')\n",
        "    plt.plot(epochs, accuracy_val, 'b', label='Validation accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDuNXsrJ4SRV"
      },
      "source": [
        "Preparing Video Data and Creating Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUeqbSjHBaCd",
        "outputId": "03440bf0-264f-42d8-8999-b181b5c8d09b"
      },
      "outputs": [],
      "source": [
        "\n",
        "f_path = '/content/fake'\n",
        "fake_videos = []\n",
        "for root, _, files in os.walk(f_path):\n",
        "    for file in files:\n",
        "        if file.endswith('.mp4'):\n",
        "            fake_videos.append(os.path.join(root, file))\n",
        "\n",
        "print(f\" Found {len(fake_videos)} fake videos.\")\n",
        "\n",
        "real_paths = ['/content/real/*.mp4']\n",
        "real_videos = []\n",
        "for path in real_paths:\n",
        "    real_videos.extend(glob.glob(path))\n",
        "\n",
        "print(f\" Found {len(real_videos)} real videos.\")\n",
        "\n",
        "all_videos = fake_videos + real_videos\n",
        "print(f\" Total videos collected: {len(all_videos)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "suQwdfEA4SRV",
        "outputId": "1f42a64f-fb6b-4a6c-ef58-03af0290ab71"
      },
      "outputs": [],
      "source": [
        "\n",
        "random.shuffle(all_videos)\n",
        "\n",
        "header_list = [\"file\", \"label\"]\n",
        "labels = pd.read_csv('labels.csv', names=header_list)\n",
        "lab = labels\n",
        "\n",
        "train_videos, valid_videos = train_test_split(all_videos, test_size=0.2)\n",
        "\n",
        "print(\"TRAIN: \", \"Real:\", number_of_real_and_fake_videos(train_videos)[0], \" Fake:\", number_of_real_and_fake_videos(train_videos)[1])\n",
        "print(\"TEST: \", \"Real:\", number_of_real_and_fake_videos(valid_videos)[0], \" Fake:\", number_of_real_and_fake_videos(valid_videos)[1])\n",
        "\n",
        "\n",
        "train_transforms, test_transforms = get_data_transforms()\n",
        "\n",
        "train_data = video_dataset(train_videos, labels, sequence_length=10, transform=train_transforms)\n",
        "val_data = video_dataset(valid_videos, labels, sequence_length=10, transform=test_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=8, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(val_data, batch_size=8, shuffle=False, num_workers=2)\n",
        "\n",
        "image, label = train_data[0]\n",
        "im_plot(image[0, :, :, :])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix2JUjEx4SRW"
      },
      "source": [
        "Training and Evaluation of the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lDVCbLoT4SRW",
        "outputId": "977c5108-9000-43eb-eb9e-360849a4475f"
      },
      "outputs": [],
      "source": [
        "lr = 1e-6\n",
        "num_epochs = 30\n",
        "model.train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "# Initialize lists to store metrics\n",
        "train_loss_avg = []\n",
        "train_accuracy = []\n",
        "test_loss_avg = []\n",
        "test_accuracy = []\n",
        "best_f1 = 0\n",
        "best_epoch = 0\n",
        "scaler = torch.amp.GradScaler('cuda')\n",
        "\n",
        "\n",
        "try:\n",
        "    print(\"Training model...\")\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        l, acc = train_epoch(epoch, num_epochs, train_loader, model, criterion, optimizer, scaler=scaler)\n",
        "        train_loss_avg.append(l)\n",
        "        train_accuracy.append(acc)\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        true, pred, tl, t_acc, precision, recall, f1, roc_auc = test(epoch, model, valid_loader, criterion)\n",
        "        test_loss_avg.append(tl)\n",
        "        test_accuracy.append(t_acc)\n",
        "\n",
        "        # Save best model\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_epoch = epoch\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "        # Early stopping\n",
        "        if epoch - best_epoch > 5:\n",
        "            print(f\"Early stopping triggered. No improvement for 5 epochs.\")\n",
        "            break\n",
        "\n",
        "except RuntimeError as e:\n",
        "    if \"NaN\" in str(e):\n",
        "        print(\"NaN detected during forward pass. Investigating...\")\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                print(f\"Layer: {name}, NaN values: {torch.isnan(param).sum().item()}\")\n",
        "    else:\n",
        "        raise e\n",
        "\n",
        "print(f\"Best F1 Score: {best_f1:.4f} achieved at epoch {best_epoch}\")\n",
        "plot_loss(train_loss_avg, test_loss_avg, len(train_loss_avg))\n",
        "plot_accuracy(train_accuracy, test_accuracy, len(train_accuracy))\n",
        "print(confusion_matrix(true, pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
